{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c4a1b56f-adf7-4568-871e-1b0e35c1cf3b",
      "metadata": {
        "id": "c4a1b56f-adf7-4568-871e-1b0e35c1cf3b"
      },
      "source": [
        "# Machine Learning (Final Project)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import some required libraries"
      ],
      "metadata": {
        "id": "8nh7Bz5kyYaR"
      },
      "id": "8nh7Bz5kyYaR"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U imbalanced-learn\n"
      ],
      "metadata": {
        "id": "G7AYxjPKAgXG",
        "outputId": "719386cb-f449-43bb-8a2b-cd44acc0220b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "G7AYxjPKAgXG",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import drive\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import IsolationForest"
      ],
      "metadata": {
        "id": "k_jtIDkSwQdo"
      },
      "id": "k_jtIDkSwQdo",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data and data preprocess"
      ],
      "metadata": {
        "id": "m8GlNfNvymKG"
      },
      "id": "m8GlNfNvymKG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "dUTeZCsb2jUa"
      },
      "id": "dUTeZCsb2jUa"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Malware_subset.csv')"
      ],
      "metadata": {
        "id": "4MiQeF4E2gxE",
        "outputId": "3d49aef3-f274-4854-b4a3-36e6a55d2d98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4MiQeF4E2gxE",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=df)\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels if needed\n",
        "plt.title(\"Boxplot for All Features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sQQQmSpRTc0o"
      },
      "id": "sQQQmSpRTc0o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "kTfpN4Dl2laC"
      },
      "id": "kTfpN4Dl2laC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89927b39-aa4f-4cc3-ac93-59d3df78b683",
      "metadata": {
        "id": "89927b39-aa4f-4cc3-ac93-59d3df78b683"
      },
      "outputs": [],
      "source": [
        "# Replace np.inf and -np.inf with NaN\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Drop np.nan numbers\n",
        "print(f\"NAN number: {df.isnull().sum()}\")\n",
        "\n",
        "# Drop duplicated data\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Duplicated data: {df.duplicated().sum()}\")\n",
        "\n",
        "# Handle missing data\n",
        "print(f\"Missing data's number: {df.isna().sum()}\")\n",
        "\n",
        "# Drop features with the full 0 or -1\n",
        "df = df.loc[:, ~((df == 0) | (df == -1)).all(axis=0)]\n",
        "\n",
        "# Label Encoder\n",
        "encoder = LabelEncoder()\n",
        "encoded = encoder.fit_transform(df['Label'])\n",
        "df['Label'] = encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Remove anomalies\n",
        "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
        "outliers = iso_forest.fit_predict(df)\n",
        "\n",
        "# Keep only normal data points\n",
        "df = df[outliers == 1]\n",
        "\n",
        "# Split the features and labels\n",
        "X = df.drop('Label', axis=1)\n",
        "y = df[\"Label\"]\n",
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Choose important features\n",
        "lasso = Lasso(alpha=0.01)\n",
        "lasso.fit(X, y)\n",
        "selected_features = X.columns[np.abs(lasso.coef_) > 0]\n",
        "X = X[selected_features]\n",
        "\n",
        "# Remove unimportant features\n",
        "selector = VarianceThreshold(threshold=0.01)\n",
        "X = selector.fit_transform(X)\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Since it's the imbalanced data, i use SMOTE to oversampling datasets\n",
        "smote = SMOTE()\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choose the model"
      ],
      "metadata": {
        "id": "hzQ3cme_zGdG"
      },
      "id": "hzQ3cme_zGdG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b7e8980-cf78-43c6-9413-bdc23a510687",
      "metadata": {
        "id": "6b7e8980-cf78-43c6-9413-bdc23a510687"
      },
      "outputs": [],
      "source": [
        "# # Use Random Forest Model\n",
        "# rf = RandomForestClassifier(n_estimators=20, random_state=42)\n",
        "# rf.fit(X_train, y_train)\n",
        "\n",
        "# # Make predictions\n",
        "# y_pred = rf.predict(X_test)\n",
        "\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "\n",
        "#Create an instance\n",
        "classifier = BalancedBaggingClassifier(estimator=RandomForestClassifier(),\n",
        "                                sampling_strategy='not majority',\n",
        "                                replacement=False,\n",
        "                                random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f1)"
      ],
      "metadata": {
        "id": "Ksa532zvQrmo"
      },
      "id": "Ksa532zvQrmo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}